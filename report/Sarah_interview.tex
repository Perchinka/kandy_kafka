
\textbf{Can you please introduce yourself and describe your experience with Kafka? }

Okay. So I'm Sarah Anderson, I'm the head of engineering at Valerann. I've been there for two, almost three years and I've worked in tech for almost 10 years. In terms of the Kafka experience, I first started working with Kafka about six years ago. This is while I was working at a marketing technology company who were using Kafka to process lots of email, like notification messages and turning them into sales automatically. But I've used Kafka in a number of different companies. I've used in about, I think, five different companies now. All for much the same purposes of high volume data processing in real time. So normally, whenever I've worked with companies in Kafka, it's usually been in a role to help them start using it, from the off and scale up. So Kafka gives you a really good ability to scale to very high levels, but to go from a traditional monolithic architecture to one built around Kafka, event-driven design; It's a large work, it's a large amount of work. It's a very different skill set, so often a lot of developers need training. Management needs to understand how building Kafka architecture works, teaching product managers, how does a product built around Kafka have to look like. So a lot of my role has been like helping people understand what is Kafka, how to use Kafka, how to build around it and how to actually learn and implement it. 

\textbf{How often do you work with Kafka now and which utilities and tools you use to manage it, to work with that?}

So I probably touch Kafka things every few days at the moment. Yeah, like three or so days. I don't have to touch the individual services all that much. Not nowadays. In terms of like what tools we use, so we use primarily a tool called Faust Streaming, which was based on another tool called Faust, which is a now-deprecated tool built by Bobbinhood. I think they're like a Bitcoin company or something. Low-band and Faust.Some people open a source to get on, including our CTO, who contributes to the project. I would not recommend the tool, and it's actually one we are moving away from instead. But up to now, it's primarily been our cycle streaming framework. So it's similar to the Kafka Streams Java framework, but built in Python and built worse. So we are slowly replacing it with our own in-house tool which we've called CitizenK. After the movie, and K because Kafka starts with a K. Otherwise we also use an open source tool for actually managing Kafka day to day, but it's like proVectus Labs UI, so they provide a free UI that we can connect to all our Kafka clusters and do any sort of administrative operations like cleaning up consumer groups, resetting offsets, things like that. And then in terms of actually managing the Kafka infrastructure, we use Terraform to actually create the clusters, create the brokers, and also to create the topics themselves and set up the initial settings for every topic. 

\textbf{Can you describe the problems that you recently encountered while using these tools for managing Kafka?
}
So, one of the most common problems we have with the admin tools is that consumer group management is never... I've never found a tool that does it well. Not as good as the actual Kafka CLI, but that's so awkward to use day to day you have to call upon bash script every time you want to use it, which is really awkward. If you want to use it for the UI, but one example is that if you want to remove a topic from a consumer group, none of the admin tools I've found can do that. You can only delete the entire consumer group or reset offsets. I don't want to do either of those, I just want to say this consumer group no longer consumes this topic, which is something that CLI supports, but no admin tool supports it. So it's really awkward to do that. 

\textbf{So you have preference of web tools instead of CLI tools. Why?}

I think with web tools, it's easier to onboard people to use them. Like it's hard to get people to read a bunch of docs to understand the tools. I personally find it harder to write internal docs around how to use CLI tools to people. I think people find it a lot easier to see pictures with circles and say "click this button". It's really obvious. While trying to write docs that say "Oh use this CLI, use this argument when you want this". It's a lot more easy So I think onboarding people who aren't experienced with Kafka is a lot easier with admin UIs. You can constrain them as well to some extent. Like, not our tool gives permissions. It's a very basic free tool. But we've also used Conductor. That lets you actually create user accounts for the admin UI with different permissions. So you could set up people so they only have read permissions. You set up people that can create. They create topics but only in a certain range. It's hard to explain because they don't do it in their own Kafka way, but they're like laying on top. But a lot of these admin tools let you constrain what the users can do. Whereas if you give them CLI access, they can just do anything. 

\textbf{Would you prefer Terminal User Interface, something like Lazydocker, or Web Interface?}

Generally I prefer a Web Interface. I know that's not true with a lot of developers. I don't know what to prefer terminals. I'm one of the unusual developers who prefers a web interface to video. I don't like using a CLI. I think a lot of people would benefit from a terminal though, especially when it's a lot easier to use than the Kafka CLI. If it's easy to install and set up on your system that's only a vast improvement over the Kafka CLI, which is really awkward to get installed and run in. And also if you just have like one, I don't know what you call it, like a root console command, where the Kafka CLI has to reference different files. So yeah, like one root and then call whatever you want it would simplify using the CLI a lot. These were the things that our admin UI can't do a simpler terminal, because it would be a lot better than having to use the Kafka CLI. 

\textbf{Can you describe your experience with working with multiple clusters simultaneously?}

So we actually have six Kafka clusters. No, we have seven Kafka clusters spread across our system and inside each of them is both like a staging and a production that is just separated by name really. But it can be quite awkward to interact with it. It'd be nice to be able to scan messages across all the different clusters, just to do a filter across all my clusters for a set of topics which is not something I've ever found a tool that can do, but it would definitely be useful for us to scan all our clusters on the topic of a particular name and filter messages like that. And also things like managing consumer groups across multiple clusters simultaneously. Like if I want to reset the offset of a consumer group in every cluster at once, that's often something we have to do in its very manual process have to go one cluster by one cluster and the more clusters there are it's easier to miss one. Similar for like deleting a topic from a consumer group so you mainly were having to go one cluster by one cluster. 

\textbf{Can you explain the process of connecting to the clusters like for making configuration files or configuring connection in your systems. How do you do this in your system and how user-friendly do you find it? }

So we have, there are three ways we really connect to Kafka. So all our services in the cloud, they're all based, they're all built in AWS. And we have an AWS secret containing Kafka credentials and it's a global secret. So we don't create capital credentials per service. All our services for a particular customer share the same set of credentials. So that's quite easy. They will just share, we never create new ones though. We obviously should create new ones and that we wouldn't be able to do easily. And it is something we definitely want to do. It's a lot of work to automate creating lots of credentials and saving them automatically.

The second way we interact with it is through our admin UI. So we don't actually run our admin UI in the cloud or anything, it runs on everyone's local machines. So we have our own internal CMI tool with a command to start that cath for the UI. So it'll start it up, reconnect it to every single cluster that we have, and then you can just browse over clusters through the UI. 

And third way we interact with it is via the Kafka CLI. Again, we have our internal CLI tool, which we've created a command to actually create the Kafka config file using the AWS Cloud Secret that is the global one that everyone needs to share.

\textbf{When thinking about how data from clusters like topics, fancy groups and others should be displayed, what are your expectations?}

Good question. I can imagine a lot of different ways that would be useful to display the data. So, if working with multiple clusters, it would be really good to be able to pull data out in whatever structure I want. So if I want to pull out data for a particular topic across every cluster, it'd be good to support that. But likewise, I may want to pull out all topics for a single cluster. It'd be good to be able to support that too. Basically, have it be highly customizable, really. So there's a lot of different visualizations we could want. Things like also being able to see, like that the minimum and maximum lag of a particular topic across all clusters or show the average, things like that. Just being able to get some stats across clusters would help us a lot because when you look at it one by one, it is hard to then compare it to the next one because you have to keep it in your head.

\textbf{Are you satisfied with current tools representation of this data? } 

I'm satisfied? No, no, no. I hate every tool I could use this is... They're all really awkward.

They'll have, they'll have like a, generally they'll have like a topic section and a consumer group section. You go into a topic, you can see the list of consumer groups. And then if you click on one of those, it then takes you into the consumer group section. There's no, you lose like where you've been. I find them quite awkward.

\textbf{Can you please describe the last Kafka related problem you solved?}

Last Kafka related problem I solved? Hmm, It's usually deliting topics and consumer groups. Most of our Kafka problems. Because we use MSK to host it, it's managed by AWS. So a lot of the Kafka specific issues that might come up, maintain your own cluster, we don't have to worry about too much, as it's AWS's problem. So it's mostly like day-to-day admin, which generally are our biggest issue keeping Kafka, keeping all the topics up to date as we change the topic structure and settings and make sure everything's in line 

% \textbf{Do you think is sorting topics by different parameters is really necessary and topics and customers by different parameters so for example you have lots of topics and I don't know for example you have
% volume that they require.}

\textbf{How important sorting these topics by volume, by different data parameters? Or is it just like in your everyday tasks you don't really care about this and just finding the topic you need and processing straight to the messages?} 

I would say it would be really useful to be able to do that. We have to keep an eye on which topics are growing in size and have a lot of messages. Lots of people, lots of our services and tools share one topic so people might one day start producing a whole load of new messages to the topic. And being able to sort the topics by how many messages or the data volume inside will be really useful so we can keep on top of which ones are now the biggest topics. I don't think our admin UI lets us actually sort the topics in any way other than by name, which isn't really useful. 

\textbf{Could you describe the top three features scenarios you would like to have in this UI tool for admin?
}

\begin{itemize}
\item Much better management of consumer groups that supports all the things the Kafka CLI supports from managing consumer groups. 
\item  Cross-cluster topic stacks, so to be able to compare the same topic across many clusters and see, how big each one is in each cluster, see average size, how many connections on each, things like that. 
\item Being able to limit what users can do. So I'm not sure how you might do that, but not everyone needs the ability to delete topics. And I definitely don't want everyone to be able to delete topics. There shouldn't be a small handful of people in the company who can delete topics. And it'd be good for the UI to prevent that rather than rely on us having set up proper security on the Kafka side. It's always good to have two sides, both enforced for same law, rather than relying entirely on Kafka enforcement at all. So being able to permission something else
\end{itemize}

Thank you.